{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "* Gradient Descent là một trong những thuật toán tối ưu hóa phổ biến và dc sử dụng rộng rãi và là một thuật toán tối ưu hóa bậc một. Tối ưu hóa bậc một có nghĩa là chúng ta chỉ tính đạo hàm bậc nhất. Như chúng ta đã thấy trong chương 1, chúng ta sử dụng gradient descent để tính toán đạo hàm bậc nhất của hàm tổn thất với weight của của neuron network để giảm thiểu hàm mất mát.\n",
    "* Gradient Descent ko chỉ áp dụng cho neuron network mà còn dc sử dụng trong các tình huống khi ta muốn tìm giá trị tồi thiểu của một hàm nào đó. Trong chương này đầu tiên chúng ta sẽ tìm hiểu về **Stochastic Gradient Descent (SGD)** và **Mini-batch gradient descent**. Sau đó chúng ta sẽ khám phá momentum dc sử dụng để tăng tốc hoặc giảm tốc đạt đạt dc sữ hội tụ.\n",
    "* Phần sau của chương này, chúng ta sẽ tìm hiểu cách tối ưu gradient descent bằng cách sử dụng các thuật toán khác nhau như Adagrad, Adadelta, RMSProp, Adam, Adamax, AMSGrad, và Nadam.\n",
    "* Chúng ta sẽ lấy một phương trình linear regression đơn giản để tìm giá trị tối thiểu của hàm mất mát linear regression bằng các thuật toán gradient descent khác nhau.\n",
    "\n",
    "# 1. Demystifying gradient descent [Hiểu rõ hơn về Gradient Descent]\n",
    "* Trước tiên, chúng ta cần hiểu function trong toán học là gì. Một function được sử dụng để thể hiện một mối quan hệ giữa input và output. Chúng ta thường sử dụng kí tự $f$ để kí hiệu cho một function. Ví dụ, $f(x) = x^2$, ngụ ý rằng function này nhận $x$ như là một input và trả về $x^2$ như là một output. Nó còn dc viết dưới dạng: $y = x^2$.\n",
    "* Tại đây, chúng ta có function $y = x^2$, chúng ta có thể visualize function này như dưới đây:<br>\n",
    "  ![](./images/03.00.png)\n",
    "* Giá trị nhỏ nhất của function dc gọi là **minimum of a function**, và như biểu đồ bên trên, minimum của function $x^2$ nằm tại $0$. Function $y = x^2$ còn dc gọi là **convex function** và ở đây chúng ta chỉ có duy nhất một minumum. Một function dc gọi là **non-convex function** khi chúng có nhiều hơn một minimum. Như hình dưới dưới đây, một non-convex function có thể có nhiều **local minimum** và một **global minimum** trong khi một convext function thì chỉ có duy nhất một global minimum:<br>\n",
    "  ![](./images/03.01.png)\n",
    "* Bằng cách nhìn vào biểu đồ, chúng ta rõ ràng thấy dc function $x^2$ đạt giá trị nhỏ nhất tại $x = 0$. Nhưng làm sao để ta tìm dc điểm này. Đầu tiên chúng ta hãy giả sử rằng $x = 0.7$, vị trị này nằm trên hình như sau:<br>\n",
    "  ![](./images/03.02.png)\n",
    "\n",
    "* Bây giờ, chúng ta cần đi đến vị trí $x = 0$, chúng ta có thể đi đến đó bằng cách lấy đạo hàm của function $y = x^2$. Vậy đạo hàm của function $y = x^2$ như sau:\n",
    "  $$y = x^2$$\n",
    "  $$\\dfrac{dy}{dx} = 2x$$\n",
    "\n",
    "* Bởi vì $x = 0.7$, khi ta thay vào phương trình đã dc đạo hàm thì ta dc:\n",
    "  $$\\dfrac{dy}{dx} = 2x = 2\\times0.7 = 1.4$$\n",
    "\n",
    "* Sau khi tính toán xong đạo hàm, chúng ta bây giờ có thể tiến hành cập nhật vị trí mới cho $x$ để tiến về minimum như sau:\n",
    "  $$x = x - \\dfrac{dy}{dx} = 0.7 - 1.4 = -0.7$$\n",
    "\n",
    "* Như chúng ta có thể thấy trong hình dưới đây, từ vị trí $x = 0.7$ nhưng sau khi chúng ta tính toán gradient thì vị trí $x$ mới sau khi cập nhật thì nó nằm tại $x = -0.7$. Tuy nhiên đây là điều mà chúng ta ko mong muốn vì chúng ta đã lỡ bỏ qua giá trị nhỏ nhất của mình tại $x = 0$ và đi đến một điểm khác.<br>\n",
    "  ![](./images/03.03.png)\n",
    "\n",
    "* Và để tránh việc $x$ cứ nhảy qua nhảy lại xung quanh điểm cực tiểu, chúng ta cần sử dụng một tham số mới gọi là learning rate $\\alpha$. Tham số $\\alpha$ giúp làm chậm các bước gradient để ta ko vô tình bỏ lỡ qua minimum. Chúng ta sẽ nhân gradient với learning rate và cập nhật vị trí mới cho nó, như sau:\n",
    "  $$x = x - \\alpha \\dfrac{dy}{dx}$$\n",
    "\n",
    "* Giả sử $\\alpha = 0.15$, lúc này $x$ mới sẽ là:\n",
    "  $$x = 0.7 - 0.15 \\times 1.4 = 0.49$$\n",
    "* Như hình dưới đây, sau khi nhận gradient với learning rate thì $x$ được cập nhật từ $x = 0.7$ xuống $x = 0.49$.<br>\n",
    "  ![](images/03.04.png)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.8"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.8 64-bit ('python3.6': conda)"
  },
  "interpreter": {
   "hash": "2cade657992b47716e26d0a9b1443bfbca37741f9a577328e2d148cb3e78348d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}