{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "* Gradient Descent là một trong những thuật toán tối ưu hóa phổ biến và dc sử dụng rộng rãi và là một thuật toán tối ưu hóa bậc một. Tối ưu hóa bậc một có nghĩa là chúng ta chỉ tính đạo hàm bậc nhất. Như chúng ta đã thấy trong chương 1, chúng ta sử dụng gradient descent để tính toán đạo hàm bậc nhất của hàm tổn thất với weight của của neuron network để giảm thiểu hàm mất mát.\n",
    "* Gradient Descent ko chỉ áp dụng cho neuron network mà còn dc sử dụng trong các tình huống khi ta muốn tìm giá trị tồi thiểu của một hàm nào đó. Trong chương này đầu tiên chúng ta sẽ tìm hiểu về **Stochastic Gradient Descent (SGD)** và **Mini-batch gradient descent**. Sau đó chúng ta sẽ khám phá momentum dc sử dụng để tăng tốc hoặc giảm tốc đạt đạt dc sữ hội tụ.\n",
    "* Phần sau của chương này, chúng ta sẽ tìm hiểu cách tối ưu gradient descent bằng cách sử dụng các thuật toán khác nhau như Adagrad, Adadelta, RMSProp, Adam, Adamax, AMSGrad, và Nadam.\n",
    "* Chúng ta sẽ lấy một phương trình linear regression đơn giản để tìm giá trị tối thiểu của hàm mất mát linear regression bằng các thuật toán gradient descent khác nhau.\n",
    "\n",
    "# 1. Demystifying gradient descent [Hiểu rõ hơn về Gradient Descent]\n",
    "* Trước tiên, chúng ta cần hiểu function trong toán học là gì. Một function được sử dụng để thể hiện một mối quan hệ giữa input và output. Chúng ta thường sử dụng kí tự $f$ để kí hiệu cho một function. Ví dụ, $f(x) = x^2$, ngụ ý rằng function này nhận $x$ như là một input và trả về $x^2$ như là một output. Nó còn dc viết dưới dạng: $y = x^2$.\n",
    "* Tại đây, chúng ta có function $y = x^2$, chúng ta có thể visualize function này như dưới đây:<br>\n",
    "  ![](./images/03.00.png)\n",
    "* Giá trị nhỏ nhất của function dc gọi là **minimum of a function**, và như biểu đồ bên trên, minimum của function $x^2$ nằm tại $0$. Function $y = x^2$ còn dc gọi là **convex function** và ở đây chúng ta chỉ có duy nhất một minumum. Một function dc gọi là **non-convex function** khi chúng có nhiều hơn một minimum. Như hình dưới dưới đây, một non-convex function có thể có nhiều **local minimum** và một **global minimum** trong khi một convext function thì chỉ có duy nhất một global minimum:<br>\n",
    "  ![](./images/03.01.png)\n",
    "* Bằng cách nhìn vào biểu đồ, chúng ta rõ ràng thấy dc function $x^2$ đạt giá trị nhỏ nhất tại $x = 0$. Nhưng làm sao để ta tìm dc điểm này. Đầu tiên chúng ta hãy giả sử rằng $x = 0.7$, vị trị này nằm trên hình như sau:<br>\n",
    "  ![](./images/03.02.png)\n",
    "\n",
    "* Bây giờ, chúng ta cần đi đến vị trí $x = 0$, chúng ta có thể đi đến đó bằng cách lấy đạo hàm của function $y = x^2$. Vậy đạo hàm của function $y = x^2$ như sau:\n",
    "  $$y = x^2$$\n",
    "  $$\\dfrac{dy}{dx} = 2x$$\n",
    "\n",
    "* Bởi vì $x = 0.7$, khi ta thay vào phương trình đã dc đạo hàm thì ta dc:\n",
    "  $$\\dfrac{dy}{dx} = 2x = 2\\times0.7 = 1.4$$\n",
    "\n",
    "* Sau khi tính toán xong đạo hàm, chúng ta bây giờ có thể tiến hành cập nhật vị trí mới cho $x$ để tiến về minimum như sau:\n",
    "  $$x = x - \\dfrac{dy}{dx} = 0.7 - 1.4 = -0.7$$\n",
    "\n",
    "* Như chúng ta có thể thấy trong hình dưới đây, từ vị trí $x = 0.7$ nhưng sau khi chúng ta tính toán gradient thì vị trí $x$ mới sau khi cập nhật thì nó nằm tại $x = -0.7$. Tuy nhiên đây là điều mà chúng ta ko mong muốn vì chúng ta đã lỡ bỏ qua giá trị nhỏ nhất của mình tại $x = 0$ và đi đến một điểm khác.<br>\n",
    "  ![](./images/03.03.png)\n",
    "\n",
    "* Và để tránh việc $x$ cứ nhảy qua nhảy lại xung quanh điểm cực tiểu, chúng ta cần sử dụng một tham số mới gọi là learning rate $\\alpha$. Tham số $\\alpha$ giúp làm chậm các bước gradient để ta ko vô tình bỏ lỡ qua minimum. Chúng ta sẽ nhân gradient với learning rate và cập nhật vị trí mới cho nó, như sau:\n",
    "  $$x = x - \\alpha \\dfrac{dy}{dx}$$\n",
    "\n",
    "* Giả sử $\\alpha = 0.15$, lúc này $x$ mới sẽ là:\n",
    "  $$x = 0.7 - 0.15 \\times 1.4 = 0.49$$\n",
    "* Như hình dưới đây, sau khi nhân gradient với learning rate thì $x$ được cập nhật từ $x = 0.7$ xuống $x = 0.49$.<br>\n",
    "  ![](images/03.04.png)\n",
    "* Tuy nhiên đây vẫn ko phải là giá trị minimum tối ưu, chúng ta cần phải đi xuống sâu hơn để đạt giá trị $x = 0$. Vậy nên, với $n$ số lần lặp, chúng ta sẽ lặp lại quá trình tương tự cho đến khi đạt dc điểm cực tiểu. Có nghĩa là, đối vs $n$ lần lặp lại, chúng ta cập nhật giá trị cho $x$ bằng cách sử dụng quy tắc cập nhật dưới đây cho đến khi đạt dc điểm cực tiểu:\n",
    "  $$x = x - \\alpha \\dfrac{dy}{dx}$$\n",
    "* Vâng, và tại sao ta lại sài dấu $-$ chứ ko phải $+$. Điều này là vì chúng ta đang tìm giá trị minimum của một function, và lúc này chúng ta cần đi xuống, lúc này nếu chúng ta cộng vào $x$ một lượng $\\alpha \\dfrac{dy}{dx}$ thì luc này chúng ta đi đi lên chức qua mỗi vòng lặp chứ ko còn là đi xuống nữa, và vì lẽ đó ta ko thể nào đạt đến cực tiểu, hãy xem hình dưới đây:<br>\n",
    "  ![](./images/03.05.png)\n",
    "* Vậy nên, qua mỗi vòng lặp, chúng ta cần tính gradient của $y$ tại $x$ bằng $\\dfrac{dy}{dx}$ và nhân giá trị gradient này cho learning rate, từ đó ta có $\\alpha \\dfrac{dy}{dx}$, sau cùng ta trừ giá trị $x$ ban đầu cho giá trị này và từ đây ta có $x$ mới.\n",
    "  $$x = x - \\alpha \\dfrac{dy}{dx}$$\n",
    "* Bằng cách lặp lại các bước này qua các vòng lặp, ta đang giảm dần cost function và đạt dc đến minimum point. Như bạn có thể thấy từ hình dưới đây, chúng ta di chuyển từ điểm khởi tạo ban đầu là $0.7$ về $0.49$ và cuối cùng chúng ta đạt $0.2$. Và sau vài vòng lặp nữa, chúng ta đạt đến minimum point là $0.0$:<br>\n",
    "  ![](images/03.06.png)\n",
    "* Chúng ta nói rằng chúng ta đạt được **convergence** [hội tụ] khi chúng ta đạt đến minimum của một function. Nhưng một câu hỏi đặt ra là làm sau để chúng ta biết dc là chúng ta đã đạt dc convergence? Trong ví dụ $y = x^2$ của chúng ta, chúng ta đã biết trc giá trị nhỏ nhất là $0.0$. Cho nên khi đạt đến $0$, chúng ta có thể nói rằng chúng ta đã tìm thấy minimum tức chúng ta đã đạt dc convergence. Nhưng trong trường hợp giả sử ta không biết bất kì thứ gì hết về function $y = x^2$ thì làm sao ta biết dc $x = 0$  chính là minimum value của function này?\n",
    "* Hãy xem xét kĩ hơn biểu đồ dưới đây, nó thể hiện $x$ thay đổi như thế nào qua mỗi vòng lặp. Như bạn có thể thấy giá trị của $x$ là $0.009$ trong lần lặp thứ 5, $0.008$ trong vòng lặp thứ 6 và $0.007$ trong lần lặp thứ 7. Như bạn thấy ko có sự thay đổi nhiều của $x$ qua các vòng lặp thứ 5, 6 và 7. Vậy khi ta nhận thấy rằng chỉ có một chút sự thay đổi của $x$ qua các vòng lặp, thì chúng ta có thể kết luận rằng chúng ta đã đạt dc convergence:<br>\n",
    "  ![](images/03.07.png)\n",
    "* OK, nhưng công dụng của tất cả những thứ này là gì? Tại sao chúng ta lại cố gắng đi tìm minimum value của một function? Vâng, khi chúng ta training model, mục đích của chúng ta là tối thiểu hóa cost function. Việc đi tìm minimum của cost function sẽ cho chúng ta một bộ **parameter** [tham số] tối ưu của model mà với bộ parameter này thì cost function của model là tối thiểu. Phương trình dưới đây được gọi là **parameter update rule** (còn dc gọi là **weight update rule**):\n",
    "  $$\\theta = \\theta - \\alpha \\times \\nabla_\\theta J(\\theta)$$\n",
    "  trong đó:\n",
    "    * $\\theta$: là parameter của model\n",
    "    * $\\alpha$: là learning rate\n",
    "    * $\\nabla_\\theta J(\\theta)$: là gradient\n",
    "* Chúng ta sẽ cập nhật bộ parameter của model qua vài vòng lặp theo quy tắc parameter update rule cho đến khi chúng ta đạt dc convergence."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.1. Performing gradient descent in regression\n",
    "* Cho đến nay, chúng ta đã hiểu cách thuật toán gradient descent tìm ra các **optimal parameter** [tham số tối ưu] cho model. Trong phần này, chúng ta sẽ tìm hiểu cách chúng ta sử dụng gradient descent trong linear regression và tìm ra optimal parameter cho nó.\n",
    "* Phương trình của một simple linear regression có thể dc mô tả như sau:\n",
    "  $$\\hat{y} = mx + b$$\n",
    "* Ở đây chúng ta có hai parameter là $m$ và $b$. Bây giờ chúng ta sẽ tìm hiểu cách sử dụng gradient descent để tìm ra optimal value cho hai parameter này."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.1.1. Importing the libraries\n",
    "* Trc tiên, chúng ta cần import các thư viện cần thiết:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.1.2. Preparing the dataset\n",
    "* Bây giờ chúng ta sẽ khởi tạo ra một vài data point bao gồm 500 dòng và 2 cột ($x$ và $y$) để sử dụng cho mục đích training."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "data = np.random.randn(500, 2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "data[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([-0.89771973,  1.16809576])"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Cột đầu tiên là $x$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "data[0, 0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-0.8977197264564211"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Cột thứ 2 là $y$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "data[0, 1]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.168095755122632"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Chúng ta biết rằng phương trình của simple linear regression có dạng:\n",
    "  $$\\hat{y} = mx + b$$\n",
    "* Cho nên, chúng ta có hai parameter là $m$ và $b$. Khi ta đặt cả hai parameter này vào cùng một array thì dc gọi là `theta`. Trc tiên, ta sẽ khởi tạo `theta` là một zero array."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "theta = np.zeros(2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Lúc này `theta[0]` là đại diện cho giá trị của $m$, `theta[1]` đại diện cho giá trị của $b$."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "theta"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0., 0.])"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.1.3. Defining the loss function\n",
    "* **Mean squared error** (**MSE**) của regression dc định nghĩa như sau:\n",
    "  $$J = \\dfrac{1}{N}\\sum_{1}^N (y - \\hat{y})^2$$\n",
    "  trong đó:\n",
    "  * $N$: là số lượng observe trong training sample\n",
    "  * $y$: là actual value\n",
    "  * $\\hat{y}$: là predicted value\n",
    "* Để cài đặt loss function MSE, chúng ta cần cung cấp `data` và `theta` cho loss function và nó sẽ trả về giá trị MSE."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "def loss_function(data, theta):\n",
    "    m = theta[0]\n",
    "    b = theta[1]\n",
    "    loss = 0\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        x = data[i, 0]\n",
    "        y = data[i, 1]\n",
    "        y_hat = m*x + b\n",
    "        loss = loss + (y - y_hat)**2\n",
    "        \n",
    "    mse = loss / float(len(data))\n",
    "    return mse"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Gọi hàm `loss_function()`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "loss_function(data, theta)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.0881370591564372"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Bây giờ, ta cần minimize giá trị của loss function. Để minimize loss function chúng ta cần tính gradient của loss function, tức $J$ đối với các parameter của model là $m$ và $b$ và cập nhật các parameter này theo parameter update rule. Bây giờ chúng ta cần tính gradient của loss function."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.1.4. Computing the gradients of the loss function\n",
    "* Gradient của loss function $J$ theo parameter $m$ dc định nghĩa như sau:\n",
    "  $$\\dfrac{dJ}{dm} = \\dfrac{2}{N}\\sum_{i = 1}^N -x_i (y_i - (mx_i + b))$$\n",
    "* Gradient của loss function $J$ theo parameter $b$ dc định nghĩa như sau:\n",
    "  $$\\dfrac{dJ}{db} = \\dfrac{2}{N}\\sum_{i = 1}^N -(y_i - (mx_i + b))$$\n",
    "* Chúng ta định nghĩa một hàm gọi là `compute_gradients`, nó lấy vào hai tham số `data` và `theta` và trả về các giá trị gradients:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "def compute_gradients(data, theta):\n",
    "    gradients = np.zeros(2)\n",
    "    N = float(len(data))\n",
    "    m = theta[0]\n",
    "    b = theta[1]\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        x = data[i, 0]\n",
    "        y = data[i, 1]\n",
    "        \n",
    "        gradients[0] += -(2/N) * x * (y - (m*x + b)) # gradient theo m\n",
    "        gradients[1] += -(2/N) * (y - (theta[0]*x + b)) # gradient theo b\n",
    "        \n",
    "    epsilon = 1e-6\n",
    "    gradients = np.divide(gradients, N + epsilon) # cộng thêm một epsilon để tránh lỗi chia cho 0\n",
    "    \n",
    "    return gradients"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "compute_gradients(data, theta)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([-3.23971237e-04, -6.27347993e-05])"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.1.5. Updating the model parameters\n",
    "* Bây giờ chúng ta đã tính dc gradient, chúng ta cần update lại các parameters của model theo parameter update rule như sau:\n",
    "  $$m = m - \\alpha \\dfrac{dJ}{dm}$$\n",
    "  $$b = b - \\alpha \\dfrac{dJ}{db}$$\n",
    "* Chúng ta lưu $m$ vào `theta[0]` và $b$ trong `theta[1]`, chúng ta sẽ update phương trình như sau:\n",
    "  $$\\theta = \\theta - \\alpha \\dfrac{dJ}{d\\theta}$$\n",
    "* Như chúng ta đã biết, việc cập nhật gradient chỉ trên một lần lặp sẽ ko dẫn chúng ta đến convergence, vì vậy chúng ta cần tính toán gradient và cập nhật các paramter của model sau một vài lần lặp:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "\n",
    "# định nghĩa số lần lặp\n",
    "num_iterations = 50000\n",
    "\n",
    "# định nghĩa learning rate\n",
    "lr = 1e-2\n",
    "\n",
    "# bây giờ chúng ta sẽ định nghĩa một list gọi là `loss` để lưu giá trị của hàm loss qua mỗi lần lặp\n",
    "loss = []\n",
    "\n",
    "theta = np.zeros(2)\n",
    "\n",
    "for t in range(num_iterations):\n",
    "    # tính gradients\n",
    "    gradients = compute_gradients(data, theta)\n",
    "    \n",
    "    # update parameter\n",
    "    theta = theta - (lr * gradients)\n",
    "    \n",
    "    loss.append(loss_function(data, theta))\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(loss)\n",
    "plt.grid()\n",
    "plt.xlabel('Traing iterations')\n",
    "plt.ylabel('Cost')\n",
    "plt.title('Gradient Descent')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.8 64-bit ('python3.6': conda)"
  },
  "interpreter": {
   "hash": "2cade657992b47716e26d0a9b1443bfbca37741f9a577328e2d148cb3e78348d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}