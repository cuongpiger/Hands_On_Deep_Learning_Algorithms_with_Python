{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Data Preparation\n",
    "* Đọc dữ liệu"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "df = pd.read_csv(\"./data/songdata.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  artist                   song                                        link  \\\n",
       "0   ABBA  Ahe's My Kind Of Girl  /a/abba/ahes+my+kind+of+girl_20598417.html   \n",
       "1   ABBA       Andante, Andante       /a/abba/andante+andante_20002708.html   \n",
       "2   ABBA         As Good As New        /a/abba/as+good+as+new_20003033.html   \n",
       "3   ABBA                   Bang                  /a/abba/bang_20598415.html   \n",
       "4   ABBA       Bang-A-Boomerang      /a/abba/bang+a+boomerang_20002668.html   \n",
       "\n",
       "                                                text  \n",
       "0  Look at her face, it's a wonderful face  \\nAnd...  \n",
       "1  Take it easy with me, please  \\nTouch me gentl...  \n",
       "2  I'll never know why I had to go  \\nWhy I had t...  \n",
       "3  Making somebody happy is a question of give an...  \n",
       "4  Making somebody happy is a question of give an...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Ahe's My Kind Of Girl</td>\n",
       "      <td>/a/abba/ahes+my+kind+of+girl_20598417.html</td>\n",
       "      <td>Look at her face, it's a wonderful face  \\nAnd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Andante, Andante</td>\n",
       "      <td>/a/abba/andante+andante_20002708.html</td>\n",
       "      <td>Take it easy with me, please  \\nTouch me gentl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>As Good As New</td>\n",
       "      <td>/a/abba/as+good+as+new_20003033.html</td>\n",
       "      <td>I'll never know why I had to go  \\nWhy I had t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang</td>\n",
       "      <td>/a/abba/bang_20598415.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang-A-Boomerang</td>\n",
       "      <td>/a/abba/bang+a+boomerang_20002668.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "df.shape[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "57650"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Số lượng nghệ sĩ"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "len(df['artist'].unique())"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "643"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Số bài hát mà từng nghệ sĩ có"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "df['artist'].value_counts()[:10]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Donna Summer        191\n",
       "Gordon Lightfoot    189\n",
       "Bob Dylan           188\n",
       "George Strait       188\n",
       "Cher                187\n",
       "Loretta Lynn        187\n",
       "Reba Mcentire       187\n",
       "Alabama             187\n",
       "Dean Martin         186\n",
       "Chaka Khan          186\n",
       "Name: artist, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Số bài hát trung bình mà một nghệ sĩ có"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "df['artist'].value_counts().values.mean()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "89.65785381026438"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Gôm tất cả bài hát lại với nhau"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "data = \", \".join(df['text'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "data[:400]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"Look at her face, it's a wonderful face  \\nAnd it means something special to me  \\nLook at the way that she smiles when she sees me  \\nHow lucky can one fellow be?  \\n  \\nShe's just my kind of girl, she makes me feel fine  \\nWho could ever believe that she could be mine?  \\nShe's just my kind of girl, without her I'm blue  \\nAnd if she ever leaves me what could I do, what could I do?  \\n  \\nAnd when we go f\""
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Chúng ta đang build một model cấp kí tự bằng RNN, nên chúng ta cần lưu các unique characters trong dataset vào `chars`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "chars = sorted(list(set(data)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "print(chars[:30])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['\\n', ' ', '!', '\"', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Lấy size của `chars` và lưu vào biến `vocab_size`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "vocab_size = len(chars)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "vocab_size"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Vì neuron network chỉ nhận đầu vào là số, nên cần chuyển đổi tất cả các kí tự này thành số.\n",
    "* Chúng ta ánh xạ tất cả các kí tự trong `chars` vào `char_to_ix` và `ix_to_char`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "char_to_ix = {ch:ix for ix, ch in enumerate(chars)} \n",
    "ix_to_char = {ix:ch for ix, ch in enumerate(chars)}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "char_to_ix['s']"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "ix_to_char[68]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'s'"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* One hot encoded vector"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "def one_hot_encoder(index):\n",
    "    return np.eye(vocab_size)[index]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "one_hot_encoder(0)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Định nghĩa các network parameters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# xác định số node trong hidden layer\n",
    "hidden_size = 100\n",
    "\n",
    "# định nghĩa chiều dài của chuổi input và output\n",
    "seq_length = 25\n",
    "\n",
    "# định nghĩa learning rate\n",
    "learning_rate = 1e-1\n",
    "\n",
    "# seed\n",
    "seed_value = 42\n",
    "tf.set_random_seed(seed_value)\n",
    "random.seed(seed_value)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Defining Placeholders\n",
    "* Định nghĩa các placeholder cho input và output"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "inputs = tf.placeholder(shape=[None, vocab_size], dtype=tf.float32, name='inputs')\n",
    "targets = tf.placeholder(shape=[None, vocab_size], dtype=tf.float32, name='targets')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Định nghĩa các placeholder cho initial hidden layer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "init_state = tf.placeholder(shape=[1, hidden_size], dtype=tf.float32, name='state')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Định nghĩa initializer các weights của RNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "initializer = tf.random_normal_initializer(stddev=0.1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Định nghĩa forward propagation\n",
    "  $$h_t = \\mathrm{tanh}(Ux_t + Wh_{t - 1} + bh)$$\n",
    "  $$\\widehat{y} = Vh_t + by$$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "with tf.variable_scope(\"RNN\") as scope:\n",
    "    h_t = init_state\n",
    "    y_hat = []\n",
    "    \n",
    "    for t, x_t in enumerate(tf.split(inputs, seq_length, axis=0)):\n",
    "        if t > 0: scope.reuse_variables()\n",
    "        \n",
    "        # input to hidden layer weights\n",
    "        U = tf.get_variable('U', [vocab_size, hidden_size], initializer=initializer)\n",
    "        \n",
    "        # hidden to hidden layer weights\n",
    "        W = tf.get_variable('W', [hidden_size, hidden_size], initializer=initializer)\n",
    "        \n",
    "        # hidden to output layer weights\n",
    "        V = tf.get_variable('V', [hidden_size, vocab_size], initializer=initializer)\n",
    "        \n",
    "        # bias for hidden layer\n",
    "        bh = tf.get_variable('bh', [hidden_size], initializer=initializer)\n",
    "        \n",
    "        # bias for output layer\n",
    "        by = tf.get_variable('by', [vocab_size], initializer=initializer)\n",
    "        \n",
    "        h_t = tf.tanh(tf.matmul(x_t, U) + tf.matmul(h_t, W) + bh)\n",
    "        \n",
    "        y_hat_t = tf.matmul(h_t, V) + by\n",
    "        y_hat.append(y_hat_t) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Apply `softmax` on the output and get the probabilities"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "output_softmax = tf.nn.softmax(y_hat[-1])\n",
    "outputs = tf.concat(y_hat, axis=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Compute the cross-entropy loss"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=targets, logits=outputs))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Store the final hidden state of the RNN in `hprev`. We use this final hidden state for making predictions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "hprev = h_t"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5. Defining BPTT\n",
    "* Bây giờ, chúng ta sẽ thực thi BPTT bằng Adam optimizer. Chúng ta cũng sẽ thực thi gradient clipping to avoid the exploding gradients problem."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "# 1. Initialize the Adam optimizer\n",
    "minimizer = tf.train.AdamOptimizer()\n",
    "\n",
    "# 2. Compute the gradients of the loss with the Adam optimizer\n",
    "gradients = minimizer.compute_gradients(loss)\n",
    "\n",
    "# 3. Set the threshold for the gradient clipping\n",
    "threshold = tf.constant(5.0, name='grad_clipping')\n",
    "\n",
    "# 4. Clip the gradients that exceed the threshold and bring it to the range\n",
    "clipped_gradients = []\n",
    "for grad, var in gradients:\n",
    "    clipped_grad = tf.clip_by_value(grad, -threshold, threshold)\n",
    "    clipped_gradients.append((clipped_grad, var))\n",
    "    \n",
    "# 5. Update the gradients with the clipped gradients\n",
    "updated_gradients = minimizer.apply_gradients(clipped_gradients)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 6. Start generating songs"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.8 64-bit ('python3.6': conda)"
  },
  "interpreter": {
   "hash": "2cade657992b47716e26d0a9b1443bfbca37741f9a577328e2d148cb3e78348d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}